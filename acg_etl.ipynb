{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/webbr1/.conda/envs/pyspark_env_dcc/lib/python3.12/site-packages/pyspark/pandas/__init__.py:50: UserWarning: 'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n",
      "  warnings.warn(\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/03/22 09:16:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/03/22 09:16:45 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from pyspark.sql import SparkSession, DataFrame, functions as F, types as T\n",
    "from pyspark.sql.window import Window\n",
    "import pyspark.pandas as ps\n",
    "\n",
    "os.environ['YARN_CONF_DIR'] = '/opt/hadoop/etc/hadoop/'\n",
    "spark = SparkSession.builder.master(\"yarn\").appName(\"acg_testing\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nspark.read.parquet('/data/pedsnet_dcc_v52/dcc_pedsnet/condition_occurrence')    .withColumn('problem_list',F.when(F.col('condition_type_concept_id').isin([2000000089,2000000090]),1).otherwise(0))    .withColumn('not_pl',F.when(F.col('condition_type_concept_id').isin([32879, 2000000089,2000000090]),0).otherwise(1))    .groupBy('site').agg(F.sum('problem_list').alias('pl'),F.sum('not_pl').alias('pl_not')).withColumn('total',F.col('pl')+F.col('pl_not')).show()\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time check\n",
    "start_time = datetime.now()\n",
    "\n",
    "cohort_start_date='2021-11-01'\n",
    "cohort_end_date='2022-10-31'\n",
    "\n",
    "person_raw = spark.read.parquet('/data/pedsnet_dcc_v52/dcc_pedsnet/person')\n",
    "person_input_df = person_raw\\\n",
    "    .filter(person_raw.gender_concept_id.isin(8507, 8532))\\\n",
    "    .withColumn('sex',F.when(F.col('gender_concept_id')==8507,'M').otherwise('F'))\\\n",
    "    .select('person_id','sex',F.col('birth_date').alias('date_of_birth'))\n",
    "\n",
    "visits_df_raw = spark.read.parquet('/data/pedsnet_dcc_v52/dcc_pedsnet/visit_occurrence')\n",
    "visits_df_intermediate = visits_df_raw\\\n",
    "    .filter(F.col('visit_concept_id').isin([9201,2000000048,2000001532, 9202,2000000469,44814711, 9203, 2000000088]))\\\n",
    "    .filter(F.col('visit_start_date').between(cohort_start_date,cohort_end_date) &\n",
    "            F.col('visit_end_date').between(cohort_start_date,cohort_end_date))\\\n",
    "    .select('visit_occurrence_id','person_id','site','visit_concept_id','visit_start_date','visit_end_date')\\\n",
    "    .withColumn('op_ed_visit',F.when(F.col('visit_concept_id').isin([9202, 44814711, 9203, 2000000048]),1).otherwise(0))\n",
    "\n",
    "\n",
    "\n",
    "persons_df = visits_df_intermediate\\\n",
    "    .join(person_input_df,on='person_id',how='inner')\\\n",
    "    .filter(F.col('op_ed_visit')>0)\\\n",
    "    .select('person_id','sex','date_of_birth')\\\n",
    "    .distinct()\\\n",
    "    .withColumn('age',F.floor(F.datediff(F.lit(cohort_end_date),F.col('date_of_birth'))/365.25).cast(T.IntegerType()))\\\n",
    "    .persist()\n",
    "\n",
    "persons_df\\\n",
    "    .select(F.col('person_id').alias('patient_id'),'sex','date_of_birth','age')\\\n",
    "    .write.csv('/data/pedsnet_dcc_v52/acg_input/patient_services',header=True,mode='overwrite')\n",
    "\n",
    "visits_df = persons_df\\\n",
    "    .select('person_id')\\\n",
    "    .join(visits_df_intermediate, 'person_id', 'inner')\\\n",
    "    .persist()\n",
    "\n",
    "#The below code chunk shows how many conditions are problem list conditions v not by site\n",
    "'''\n",
    "spark.read.parquet('/data/pedsnet_dcc_v52/dcc_pedsnet/condition_occurrence')\\\n",
    "    .withColumn('problem_list',F.when(F.col('condition_type_concept_id').isin([2000000089,2000000090]),1).otherwise(0))\\\n",
    "    .withColumn('not_pl',F.when(F.col('condition_type_concept_id').isin([32879, 2000000089,2000000090]),0).otherwise(1))\\\n",
    "    .groupBy('site').agg(F.sum('problem_list').alias('pl'),F.sum('not_pl').alias('pl_not')).withColumn('total',F.col('pl')+F.col('pl_not')).show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "conditions_df_raw = spark.read.parquet('/data/pedsnet_dcc_v52/dcc_pedsnet/condition_occurrence')\n",
    "concept_df_raw = spark.read.parquet('/data/pedsnet_dcc_v52/vocabulary/concept') \n",
    "concept_relationship_df_raw = spark.read.parquet('/data/pedsnet_dcc_v52/vocabulary/concept_relationship') \n",
    "\n",
    "#map the vocabulary_ids to the ACG equivalent\n",
    "#NOTE: ICD9CM may not be appropriate to map to 9, which is meant to be ICD9. check with Chris.\n",
    "vocab_dict = {'ICD10':'10', 'ICD10CM':'10CM', 'ICD9CM':'9','SNOMED':'S'}\n",
    "map_col = F.create_map([F.lit(x) for i in vocab_dict.items() for x in i])\n",
    "\n",
    "concept_df = concept_df_raw\\\n",
    "    .filter(F.col('vocabulary_id').isin(['SNOMED','ICD9CM','ICD10CM','ICD10']))\\\n",
    "    .withColumn('dx_version', map_col[F.col('vocabulary_id')])\\\n",
    "    .select(concept_df_raw.concept_id.alias('condition_source_concept_id'),\n",
    "            concept_df_raw.concept_code.alias('dx_cd'),\n",
    "            'dx_version')\n",
    "\n",
    "window = Window.partitionBy('visit_occurrence_id')\n",
    "\n",
    "# Get all conditions with the our cohorts visits, remove those that are registry or problem list conditions,\n",
    "# then limit conditions to those with the highest \"certainty\" for each visit \n",
    "# Most to least certain: Final Diagnosis, Clinical Diagnosis, Admitting Diagnosis, Null/No matching concept\n",
    "# Avg conditions per visit anywhere from 2.8 (national) to 6.5 (Lurie)\n",
    "medical_services_df_raw = visits_df.select(\"visit_occurrence_id\")\\\n",
    "    .join(conditions_df_raw,on='visit_occurrence_id',how='inner')\\\n",
    "    .filter(~F.col('condition_type_concept_id').isin([32879, 2000000089,2000000090]))\\\n",
    "    .withColumn('condition_status_order', \n",
    "                F.when(F.col('condition_status_concept_id').eqNullSafe(4230359),1)\\\n",
    "                .when(F.col('condition_status_concept_id').eqNullSafe(4309119),2)\\\n",
    "                .when(F.col('condition_status_concept_id').eqNullSafe(4203942),3)\\\n",
    "                .otherwise(4))\\\n",
    "    .withColumn('condition_status_filter',F.rank().over(window.orderBy(\"condition_status_order\")))\\\n",
    "    .filter(F.col('condition_status_filter').eqNullSafe(1))\\\n",
    "    .select('visit_occurrence_id','site','condition_status_concept_id','condition_source_concept_id')\\\n",
    "    .distinct()\\\n",
    "    .withColumn('dx_n',F.row_number().over(window.orderBy('site')))\\\n",
    "    .withColumn('dx_n_ceiling',F.when(~(F.col('dx_n')%10==0),F.col('dx_n')%10).otherwise(10))\\\n",
    "    .withColumn('visit_dummy',F.floor((F.col('dx_n')-1)/10))\\\n",
    "    .repartition('visit_occurrence_id')\\\n",
    "    .join(F.broadcast(concept_df),on='condition_source_concept_id',how='inner')\\\n",
    "    .persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[condition_source_concept_id: int, visit_occurrence_id: bigint, site: string, condition_status_concept_id: int, dx_n: int, dx_n_ceiling: int, visit_dummy: bigint, dx_cd: string, dx_version: string]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pivoted_df= None\n",
    "dx_n_list = sorted([int(row.dx_n_ceiling) for row in medical_services_df_raw.select('dx_n_ceiling').distinct().collect()])\n",
    "for i in dx_n_list:\n",
    "    dx_codes = medical_services_df_raw.filter(F.col('dx_n_ceiling')==i)\\\n",
    "                .select(medical_services_df_raw.visit_occurrence_id,\n",
    "                        medical_services_df_raw.visit_dummy,\n",
    "                        medical_services_df_raw.dx_cd.alias('dx_cd_'+str(i)),\n",
    "                        medical_services_df_raw.dx_version.alias('dx_version_'+str(i)))\n",
    "    if isinstance(pivoted_df, DataFrame):\n",
    "        pivoted_df = pivoted_df.join(dx_codes,on=['visit_occurrence_id','visit_dummy'],how='left')\n",
    "        \n",
    "    else:\n",
    "        pivoted_df = dx_codes\n",
    "\n",
    "\n",
    "join_visits = visits_df\\\n",
    "    .withColumn('service_place',\n",
    "                F.when(F.col('visit_concept_id').isin([9201,2000000048,2000001532]),'IP')\\\n",
    "                .when(F.col('visit_concept_id').isin([9202,2000000469,44814711]),'OP')\\\n",
    "                .when(F.col('visit_concept_id').eqNullSafe(9203),'ED').otherwise('OBS'))\\\n",
    "    .select(F.col(\"person_id\").alias('patient_id'), \"site\", \"visit_occurrence_id\", \n",
    "            \"service_place\", F.col(\"visit_start_date\").alias('service_begin_date'), F.col(\"visit_end_date\").alias('service_end_date'))\n",
    "\n",
    "medical_services_df = pivoted_df.join(join_visits,on='visit_occurrence_id',how='inner')\n",
    "\n",
    "medical_services_df.drop('visit_occurrence_id','visit_dummy').write.csv('/data/pedsnet_dcc_v52/acg_input/medical_services',header=True,mode='overwrite')\n",
    "medical_services_df_raw.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[person_id: bigint, sex: string, date_of_birth: date, age: int]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "concept_relationship_df_raw = spark.read.parquet('/data/pedsnet_dcc_v52/vocabulary/concept_relationship') \n",
    "rx_norm_concepts = concept_df_raw.filter(concept_df_raw.vocabulary_id.isin(['RxNorm','RxNorm Extension'])).select(F.col('concept_id').alias('concept_id_rxnorm'))\n",
    "ndc_concepts= concept_df_raw.filter(concept_df_raw.vocabulary_id.eqNullSafe('NDC')).select('concept_id','concept_code')\n",
    "\n",
    "w = Window().partitionBy(\"concept_id_rxnorm\").orderBy(\"concept_id\")\n",
    "rxnorm_ndc_map = concept_relationship_df_raw\\\n",
    "    .filter(F.col('relationship_id').eqNullSafe('Maps to'))\\\n",
    "    .join(rx_norm_concepts,on=F.col('concept_id_1')==F.col('concept_id_rxnorm'),how='inner')\\\n",
    "    .join(ndc_concepts,\n",
    "        on=F.col('concept_id_2')==F.col('concept_id'),how='inner')\\\n",
    "    .select(F.col('concept_id_rxnorm'),F.first('concept_id').over(w).alias('concept_id_ndc'),'concept_code')\\\n",
    "    .distinct()\n",
    "\n",
    "drug_exposure_raw = spark.read.parquet('/data/pedsnet_dcc_v52/dcc_pedsnet/drug_exposure')\n",
    "drug_exposure_input = visits_df\\\n",
    "    .select(\"visit_occurrence_id\")\\\n",
    "    .join(drug_exposure_raw,on='visit_occurrence_id',how='inner')\\\n",
    "    .select('person_id','site','visit_occurrence_id','drug_exposure_start_date',F.col('drug_concept_id').alias('concept_id'))\\\n",
    "    .persist()\n",
    "\n",
    "ndc_rx = drug_exposure_input\\\n",
    "    .join(ndc_concepts.select('concept_id','concept_code'),on='concept_id',how='inner')\\\n",
    "    .select('person_id','site','drug_exposure_start_date','concept_id','concept_code')\n",
    "rxnorm_rx_mapped = drug_exposure_input\\\n",
    "    .join(rxnorm_ndc_map.select('concept_id_rxnorm','concept_id_ndc','concept_code'),\n",
    "        on=F.col('concept_id')==F.col('concept_id_rxnorm'),\n",
    "        how='inner').select('person_id','site','drug_exposure_start_date',F.col('concept_id_ndc').alias('concept_id'),'concept_code')\n",
    "\n",
    "pharmacy = ndc_rx.union(rxnorm_rx_mapped)\\\n",
    "    .select(F.col('person_id').alias('patient_id'),\n",
    "            F.col('concept_code').alias('rx_cd'),\n",
    "            F.col('drug_exposure_start_date').alias('rx_fill_date'),\n",
    "            'site')\\\n",
    "    .withColumn('rx_code_type',F.lit('N'))\n",
    "\n",
    "pharmacy.write.csv('/data/pedsnet_dcc_v52/acg_input/pharmacy_services',header=True,mode='overwrite')\n",
    "\n",
    "drug_exposure_input.unpersist()\n",
    "visits_df.unpersist()\n",
    "persons_df.unpersist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:41:30.920329\n"
     ]
    }
   ],
   "source": [
    "#about 27 minutes 12 seconds, minimal resource allocation (~1% of cluster)\n",
    "print(datetime.now()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "cdm_tbl('visit_occurrence') %>% \n",
    "    filter(visit_concept_id %in% c(9201,9202,9203,44814711,2000000048,2000001532) & \n",
    "             visit_start_date>=as.Date('2022-01-01') &\n",
    "             visit_start_date<as.Date('2023-01-01')) %>% \n",
    "    select(visit_occurrence_id) %>% \n",
    "    inner_join(cdm_tbl('condition_occurrence') %>% \n",
    "                 select(condition_occurrence_id,condition_concept_id,condition_source_concept_id,visit_occurrence_id,site,\n",
    "                        condition_status_concept_id,condition_status_concept_name,\n",
    "                        condition_type_concept_id,condition_status_concept_id,\n",
    "                        condition_status_concept_name),by='visit_occurrence_id') %>%\n",
    "    inner_join(vocabulary_tbl('concept') %>%\n",
    "                 select(concept_id,concept_code,vocabulary_id),\n",
    "               by=c('condition_source_concept_id'='concept_id')) %>%\n",
    "    filter(!grepl('9',vocabulary_id,ignore.case = TRUE)) %>%\n",
    "    mutate(condition_status_order=\n",
    "             case_when(is.na(condition_status_concept_id) | condition_status_concept_id==0 ~ 4,\n",
    "                       condition_status_concept_id==4203942 ~ 3,\n",
    "                       condition_status_concept_id==4309119 ~ 2,\n",
    "                       condition_status_concept_id==4230359 ~ 1)) %>%\n",
    "    group_by(visit_occurrence_id) %>% \n",
    "    filter(condition_status_order==min(condition_status_order)) %>% ungroup() %>%\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark_env_dcc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
